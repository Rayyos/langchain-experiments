{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEMINI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.environ.get('GOOGLE_GEMINI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Call Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the package\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(api_key=GOOGLE_API_KEY, model=\"gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Washington, D.C.\n",
      "Total Tokens Used: 15\n"
     ]
    }
   ],
   "source": [
    "# Define the question to ask the language model\n",
    "question = \"What is the capital of USA?\"\n",
    "\n",
    "# Invoke the language model with the question\n",
    "response = llm.invoke(question)\n",
    "\n",
    "# Extract key components from the response\n",
    "content = response.content  # AI's response text\n",
    "total_tokens = response.usage_metadata[\"total_tokens\"]  # Total tokens used in the response\n",
    "\n",
    "# Print the results\n",
    "print(f\"Response: {content}\")\n",
    "print(f\"Total Tokens Used: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Example: Prompt Template + LLm\n",
    "The most fundamental and commonly used case involves linking a prompt template with a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "# Define the prompt template\n",
    "template = 'What is the capital of {country}?'\n",
    "prompt_template = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of india?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the prompt.\n",
    "prompt = prompt_template.format(country=\"india\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain Creation\n",
    "LCEL (LangChain Expression Language)\n",
    "Here, we use LCEL to combine various components into a single chain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"Please explain {topic} in simple terms.\")\n",
    "# Combine the prompt and model into a chain\n",
    "model = ChatGoogleGenerativeAI(api_key=GOOGLE_API_KEY, model=\"gemini-1.5-pro\")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\"topic\": \"The Principles of Learning in Artificial Intelligence Models\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Imagine teaching a dog a trick. You use treats (rewards) and corrections to shape their behavior. AI learning is similar, but instead of a dog, it\\'s a computer program, and instead of treats, it\\'s data and algorithms. Here are the basic principles:\\n\\n1. **Supervised Learning (Learning with a Teacher):**  You show the AI lots of labeled examples, like pictures of cats labeled \"cat\" and dogs labeled \"dog.\" The AI learns the patterns to identify new pictures as either \"cat\" or \"dog.\"  Think of it like flashcards.\\n\\n2. **Unsupervised Learning (Learning without a Teacher):**  You give the AI a bunch of data *without* labels. It has to figure out the patterns and relationships on its own, like grouping similar customers together based on their purchase history.  Think of it like sorting a pile of LEGOs by color and shape without instructions.\\n\\n3. **Reinforcement Learning (Learning through Trial and Error):**  You let the AI try different actions in an environment and give it rewards or penalties based on its performance.  Like teaching a dog to sit by giving it a treat when it does it correctly.  Think of it like playing a video game and getting points for doing well.\\n\\n4. **Generalization (Applying what\\'s learned):** The goal isn\\'t just to memorize the training data, but to learn underlying principles that can be applied to *new*, unseen data. Like the dog learning to sit on command even in a new location.\\n\\n5. **Error Minimization (Learning from Mistakes):**  AI models constantly adjust their internal parameters to reduce errors in their predictions. The closer they get to the right answer, the better the model becomes.  Think of it like practicing a musical instrument and getting better with each attempt.\\n\\n6. **Overfitting (Memorizing instead of Learning):** Sometimes, the AI learns the training data *too* well, including its specific quirks and noise. This makes it perform poorly on new data.  Think of it like a student memorizing the entire textbook but not understanding the concepts.\\n\\n7. **Regularization (Preventing Overfitting):**  Techniques are used to prevent overfitting by encouraging the model to find simpler, more general solutions.  Think of it like a teacher giving simpler practice problems before a difficult test.\\n\\n\\nThese principles guide how AI models learn from data and improve their performance over time, allowing them to accomplish tasks like image recognition, language translation, and game playing.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-1ba8cca3-76f0-417c-9638-bed570b7fa33-0', usage_metadata={'input_tokens': 15, 'output_tokens': 519, 'total_tokens': 534, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine training a dog. You wouldn't expect it to understand complex commands right away.  AI models learn similarly, building up knowledge gradually through different \"training\" methods. Here are some key principles:\n",
      "\n",
      "* **Supervised Learning:**  Like showing your dog a treat and saying \"sit,\" you give the AI labeled examples (input data with the correct answer).  It learns to connect the input with the desired output. Example: Showing an AI pictures of cats and dogs, labeled as such, so it can learn to identify them.\n",
      "\n",
      "* **Unsupervised Learning:**  This is like letting your dog explore the park and figure things out on its own.  You give the AI unlabeled data and it finds patterns, relationships, and structures within the data itself.  Example: Grouping customers based on their purchasing habits without knowing their demographics beforehand.\n",
      "\n",
      "* **Reinforcement Learning:** This is like rewarding your dog for good behavior. The AI learns through trial and error by interacting with an environment. It gets \"rewards\" for correct actions and \"penalties\" for wrong ones. Example: Training a robot to navigate a maze, rewarding it for reaching the end.\n",
      "\n",
      "* **Generalization:** A well-trained dog can \"sit\" even in a new environment. Similarly, a good AI model can apply what it learned to new, unseen data. This ability to generalize is crucial for real-world applications.\n",
      "\n",
      "* **Overfitting:**  If you only train your dog in your living room, it might not \"sit\" at the park.  Overfitting happens when the AI learns the training data *too* well, including its noise and specificities, and performs poorly on new data.\n",
      "\n",
      "* **Underfitting:** If you don't train your dog enough, it won't learn \"sit\" at all. Underfitting is when the model is too simple to capture the underlying patterns in the data, leading to poor performance on both training and new data.\n",
      "\n",
      "* **Bias and Fairness:** Just like a dog trainer might unknowingly favor certain breeds, AI models can inherit biases from the data they're trained on. This can lead to unfair or discriminatory outcomes. Addressing bias is a crucial ethical consideration in AI development.\n",
      "\n",
      "\n",
      "These principles guide how AI models learn and improve, allowing them to perform tasks from image recognition to language translation and even playing complex games."
     ]
    }
   ],
   "source": [
    "# Request for Streaming Output\n",
    "answer = chain.stream(input)\n",
    "\n",
    "# Streaming Output\n",
    "for token in answer:\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Parser\n",
    "An Output Parser is a tool designed to transform or process the responses from an AI model into a specific format. Since the model's output is typically provided as free-form text, an Output Parser is essential to convert it into a structured format or extract the required data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a seasoned English teacher with 10 years of experience. Please write an English conversation suitable for the given situation.  \n",
    "Refer to the [FORMAT] for the structure.\n",
    "\n",
    "#SITUATION:\n",
    "{question}\n",
    "\n",
    "#FORMAT:\n",
    "- Dialogue in English:\n",
    "- Explanation of the Dialogue: \n",
    "\"\"\"\n",
    "\n",
    "# Generate the prompt using the PromptTemplate\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(api_key=GOOGLE_API_KEY, model=\"gemini-1.5-pro\")\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Dialogue in English:**\n",
      "\n",
      "**Waiter:** Good evening, welcome to The Golden Spoon. Do you have a reservation?\n",
      "\n",
      "**Customer:** Good evening. No, we don't.  A table for two, please.\n",
      "\n",
      "**Waiter:**  Right this way.  (Leads them to a table) Here you are. Your menus. I'll be back in a moment to take your order.\n",
      "\n",
      "**(A few minutes later)**\n",
      "\n",
      "**Waiter:** Are you ready to order?\n",
      "\n",
      "**Customer:** Yes, I think so.  I'll have the grilled salmon with the roasted vegetables, please.\n",
      "\n",
      "**Waiter:** And for you, sir?\n",
      "\n",
      "**Customer 2:** I'm having trouble deciding between the steak and the pasta primavera.  What would you recommend?\n",
      "\n",
      "**Waiter:** The steak is very popular. It's a ribeye, cooked to your liking.\n",
      "\n",
      "**Customer 2:** Okay, I'll go with the ribeye, medium-rare, please.\n",
      "\n",
      "**Waiter:** Excellent choices.  And for sides?\n",
      "\n",
      "**Customer:** Could I have a side salad with the vinaigrette dressing?\n",
      "\n",
      "**Customer 2:** I'll have the mashed potatoes.\n",
      "\n",
      "**Waiter:** Certainly.  Anything to drink?\n",
      "\n",
      "**Customer:** Just water for me, please.\n",
      "\n",
      "**Customer 2:** I'll have a glass of your house red wine.\n",
      "\n",
      "**Waiter:** Very good. I'll bring your drinks right away and your food will be out shortly.\n",
      "\n",
      "**(Later, after the meal)**\n",
      "\n",
      "**Waiter:** How was everything?\n",
      "\n",
      "**Customer:** Delicious, thank you.\n",
      "\n",
      "**Customer 2:**  The steak was cooked perfectly.\n",
      "\n",
      "**Waiter:** I'm glad to hear it. Would you like to see the dessert menu?\n",
      "\n",
      "**Customer:**  No, thank you. Just the bill, please.\n",
      "\n",
      "**Waiter:** Certainly.  (Brings the bill)\n",
      "\n",
      "\n",
      "- **Explanation of the Dialogue:**\n",
      "\n",
      "This dialogue covers a typical restaurant interaction from arrival to paying the bill.  It uses common restaurant vocabulary and phrases such as \"reservation,\" \"table for two,\" \"menu,\" \"order,\" \"sides,\" \"cooked to your liking,\" \"house wine,\" and \"bill.\"\n",
      "\n",
      "* **Greeting and Seating:** The waiter greets the customers and asks about a reservation, a standard practice in many restaurants.  The customers request a table and are led to their seats.\n",
      "\n",
      "* **Ordering:** The waiter returns to take their order. One customer orders directly, while the other asks for a recommendation, demonstrating a common scenario.  The dialogue also includes specifying cooking preferences (medium-rare) and requesting specific sides and dressings.\n",
      "\n",
      "* **Drinks:** The dialogue includes ordering both alcoholic and non-alcoholic beverages, showing variety in choices.\n",
      "\n",
      "* **Checking In and Bill:** The waiter checks on the customers after the meal, a polite way to ensure satisfaction.  The customers express their enjoyment of the food, and finally, the bill is requested.\n",
      "\n",
      "* **Formal vs. Informal:** The language used is polite and relatively formal, appropriate for interacting with a waiter.  While more informal language could be used among friends dining together, this dialogue maintains a respectful tone suitable for a restaurant setting.\n",
      "\n",
      "* **Realism:** The dialogue avoids overly complex sentences and uses natural, everyday language.  This makes it a practical example for English learners to practice ordering in a restaurant. This dialogue also incorporates common occurrences like asking for recommendations and specifying preferences, making it more realistic.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"question\": \"I want to go to a restaurant and order food.\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Dialogue in English:**\n",
      "\n",
      "**Waiter:** Good evening, welcome to The Golden Spoon. Do you have a reservation?\n",
      "\n",
      "**Customer:** Good evening. No, we don't.  A table for two, please.\n",
      "\n",
      "**Waiter:** Right this way.  (Leads them to a table)  Here are your menus.  Can I get you anything to drink while you look?\n",
      "\n",
      "**Customer:**  I'd like a glass of iced tea, please.\n",
      "\n",
      "**Customer 2:** I'll have a sparkling water, no lemon.\n",
      "\n",
      "**Waiter:** Certainly.  I'll be back with your drinks in a moment. (Leaves)\n",
      "\n",
      "**(A few minutes later, the waiter returns with the drinks.)**\n",
      "\n",
      "**Waiter:** Here you are. Are you ready to order?\n",
      "\n",
      "**Customer:** Yes, I think so. I'll have the grilled salmon with the roasted vegetables.\n",
      "\n",
      "**Customer 2:**  I'm having trouble deciding... Could you tell me what the soup of the day is?\n",
      "\n",
      "**Waiter:**  The soup of the day is creamy tomato basil.\n",
      "\n",
      "**Customer 2:**  Hmm, that sounds lovely.  I'll have that to start, and then the chicken Caesar salad, please.\n",
      "\n",
      "**Waiter:**  Excellent choices.  The salmon comes with a choice of potato or rice.  Which would you prefer?\n",
      "\n",
      "**Customer:**  I'll take the rice, please.\n",
      "\n",
      "**Waiter:**  Alright. So that's grilled salmon with rice and roasted vegetables, creamy tomato basil soup, and a chicken Caesar salad.  I'll put that order in for you right away.\n",
      "\n",
      "**Customer:** Thank you.\n",
      "\n",
      "**Waiter:** You're welcome.\n",
      "\n",
      "\n",
      "- **Explanation of the Dialogue:**\n",
      "\n",
      "This dialogue covers the common stages of ordering food at a restaurant.\n",
      "\n",
      "* **Greeting and Seating:** The waiter greets the customer and asks about a reservation.  The customer indicates they need a table for two. The waiter then leads them to a table and provides menus.\n",
      "* **Drinks Order:** The waiter offers drinks while the customers peruse the menu. This is standard practice in many restaurants. Note the specific requests for \"iced tea\" and \"sparkling water, no lemon\" which demonstrate how to make specific drink orders.\n",
      "* **Taking the Order:** The waiter returns with the drinks and asks if the customers are ready. This provides a natural transition to ordering the food.\n",
      "* **Clarifying and Making Choices:** One customer asks about the soup of the day, a common question.  The waiter provides the information, and the customer makes their choice.  The other customer's order requires a further choice (potato or rice), which the waiter clarifies.\n",
      "* **Confirmation:** The waiter repeats the entire order back to the customers. This is crucial for ensuring accuracy and avoiding mistakes.  It also allows the customers a final chance to correct any errors.\n",
      "* **Polite Ending:** The customers thank the waiter, and the waiter responds with a polite acknowledgement.\n",
      "\n",
      "This dialogue utilizes simple yet effective language, making it suitable for English learners.  It also incorporates polite phrases like \"please\" and \"thank you,\" which are important for demonstrating good manners in a restaurant setting.  The vocabulary used is related to dining, providing useful practice for learners in this specific context. The dialogue also models how to handle common situations like asking about specials and making specific requests."
     ]
    }
   ],
   "source": [
    "# Execute the completed Chain to obtain a response\n",
    "# Request for Streaming Output\n",
    "answer = chain.stream({\"question\": \"I want to go to a restaurant and order food.\"})\n",
    "\n",
    "# Streaming Output\n",
    "for token in answer:\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
